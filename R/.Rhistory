anova(model2, model)
par(mfrow = c(2, 2))
plot(model2)
confint(model2)
dim(Carseats)
summary(model2)
c(-0.057825 - qnorm(0.95) * 0.003938, -0.057825 + qnorm(0.95) * 0.003938)
c(-0.057825 - qt(0.95, 395) * 0.003938, -0.057825 + qt(0.95, 395) * 0.003938)
c(-0.057825 - qt(0.975, 395) * 0.003938, -0.057825 + qt(0.975, 395) * 0.003938)
c(-0.057825 - qnorm(0.975) * 0.003938, -0.057825 + qnorm(0.975) * 0.003938)
?confint
confint(model2, level = 0.95)
confint(model2, level = 0.975)
confint(model2, level = 0.95)
c(-0.057825 - qnorm(0.025) * 0.003938, -0.057825 + qnorm(0.025) * 0.003938)
confint(model2, level = 0.95)
c(-0.057825 - qnorm(0.95) * 0.003938, -0.057825 + qnorm(0.95) * 0.003938)
cor(Carseats)
?cor
cor(Carseats, use = "everything")
cor(names(Carseats))
cor(Sales, Price, US, ShelveLoc)
cor(Sales, Price, US, ShelveLoc)
cor(Carseats)
cor(subset(Carseats, c("Sales", "Price")))
cor(subset(Carseats, select = c("Sales", "Price")))
cor(subset(Carseats, select = c("Sales", "Price", "US", "ShelveLoc")))
cor(subset(Carseats, select = c("Sales", "Price", "ShelveLoc")))
cor(subset(Carseats, select = c("Sales", "Price")))
model3 = lm(Sales ~ Price * ShelveLoc + US, data = Carseats)
summary(model3)
# Change baseline level of ShelveLoc from Bad to Good
new.shelveloc2 = relevel(ShelveLoc, ref = "Good")
rm(list = ls())
data("mtcars")
names(mtcars)
?mtcars
View(mtcars)
dim(mtcars)
attach(mtcars)
is.factor(vs)
is.factor(am)
mtcars$am = as.factor(am)
is.factor(am)
is.factor(mtcars$am)
attach(mtcars)
attach(mtcars)
is.factor(am)
mtcars$vs = as.factor(vs)
mtcars$am = as.factor(am)
attach(mtcars)
is.factor(am)
is.factor(vs)
boxplot(mpg ~ vs)
boxplot(mpg ~ vs)
boxplot(mpg ~ vs, xlab = "vs", ylab = "mpg")
boxplot(mpg ~ vs * am, ylab = "mpg", xlab = "vs & am")
model = glm(vs ~ mpg * am, data = mtcars, family = binomial)
summary(model)
model2 = glm(vs ~ mpg + am, family = binomial, data = mtcars)
summary(model2)
confint(model2)
confint(model2, level = 0.9)
coefs = coef(model2)
var(model2)
vcov(model2)
se = sqrt(diag(vcov(model2)))
c(coefs[2] - qnorm(0.9) * se[2], coefs[2] + qnorm(0.9) * se[2])
c(coefs[2] - qt(0.9, 29) * se[2], coefs[2] + qt(0.9, 29) * se[2])
c(coefs[2] - qt(0.9, df = 29) * se[2], coefs[2] + qt(0.9, df = 29) * se[2])
c(coefs[2] - qt(0.95, 29) * se[2], coefs[2] + qt(0.95, 29) * se[2])
confint(model2, level = 0.9)
c(coefs[2] - qnorm(0.9) * se[2], coefs[2] + qnorm(0.9) * se[2])
c(coefs[2] - qnorm(1.9) * se[2], coefs[2] + qnorm(1.9) * se[2])
c(coefs[2] - qnorm((1+ 0.9) / 2) * se[2], coefs[2] + qnorm((1 + 0.9) / 2) * se[2])
qnorm(1.9 / 2)
c(coefs[2] - qnorm(1.9 / 2) * se[2], coefs[2] + qnorm(1.9 / 2) * se[2])
qnorm(1.9 / 2)
qnorm(0.9)
c(coefs[2] - qnorm((1 + 0.9) / 2) * se[2], coefs[2] + qnorm((1 + 0.9) / 2) * se[2])
confint(model2, level = 0.9)
?qt
summary(model2)
1-pchisq(20.646, 29)
model3 = glm(vs ~ mpg, data = mtcars, family = binomial())
summary(model3)
anova(model3, model2, test = "Chisq")
1 - pchisq(25.533 - 20.646, 1) # p-value of the deviance difference
pred = predict(model2)
head(pred)
pred = model2$fitted.values
head(pred)
pred = predict(model2)
head(pred)
est.values = predict(model2)
head(est.values)
est.probs = predict(model2, type = "response")
head(est.probs)
model2$fitted.values
head(est.probs)
head(model2$fitted.values)
plot(mpg, vs, col = am, xlab = "mpg", ylab = "vs")
curve(predict(model2, newdata = data.frame(mpg = x, am = "0"), type = "response"), add = TRUE)
x
curve(predict(model2, newdata = data.frame(mpg = x, am = "0"), type = "response"))
plot(mpg, vs, col = am, xlab = "mpg", ylab = "vs")
curve(predict(model2, newdata = data.frame(mpg = mpg[am = "0"], am = "0"), type = "response"), add = TRUE)
curve(predict(model2, newdata = data.frame(mpg = mpg[am = 0], am = "0"), type = "response"), add = TRUE)
curve(predict(model2, newdata = data.frame(mpg = x, am = 0), type = "response"), add = TRUE)
curve(predict(model2, newdata = data.frame(mpg = x, am = "0"), type = "response"), add = TRUE)
vs
plot(mpg, vs, col = am, xlab = "mpg", ylab = "vs")
vs
rm(list = ls())
data("mtcars")
names(mtcars)
View(mtcars)
dim(mtcars)
attach(mtcars)
is.factor(am)
mtcars$am = as.factor(am)
attach(mtcars)
boxplot(mpg ~ vs, xlab = "vs", ylab = "mpg")
boxplot(mpg ~ vs * am, ylab = "mpg", xlab = "vs & am")
model = glm(vs ~ mpg * am, data = mtcars, family = binomial)
summary(model)
model2 = glm(vs ~ mpg + am, family = binomial, data = mtcars)
summary(model2)
coefs = coef(model2)
se = sqrt(diag(vcov(model2)))
c(coefs[2] - qnorm((1 + 0.9) / 2) * se[2], coefs[2] + qnorm((1 + 0.9) / 2) * se[2])
confint(model2, level = 0.9)
# accuracy of model on the basis of the deviance
1-pchisq(20.646, 29)
model3 = glm(vs ~ mpg, data = mtcars, family = binomial())
summary(model3)
anova(model3, model2, test = "Chisq")
1 - pchisq(25.533 - 20.646, 1) # p-value of the deviance difference
est.values = predict(model2)
head(est.values)
est.probs = predict(model2, type = "response") # or model2$fitted.values
head(est.probs)
plot(mpg, vs, col = am, xlab = "mpg", ylab = "vs")
curve(predict(model2, newdata = data.frame(mpg = x, am = "0"), type = "response"), add = TRUE)
rm(list = ls())
data("mtcars")
names(mtcars)
dim(mtcars)
attach(mtcars)
is.factor(am)
mtcars$am = as.factor(am)
attach(mtcars)
boxplot(mpg ~ vs, xlab = "vs", ylab = "mpg")
boxplot(mpg ~ vs * am, ylab = "mpg", xlab = "vs & am")
model = glm(vs ~ mpg * am, data = mtcars, family = binomial)
summary(model)
model2 = glm(vs ~ mpg + am, family = binomial, data = mtcars)
summary(model2)
coefs = coef(model2)
se = sqrt(diag(vcov(model2)))
c(coefs[2] - qnorm((1 + 0.9) / 2) * se[2], coefs[2] + qnorm((1 + 0.9) / 2) * se[2])
confint(model2, level = 0.9)
# accuracy of model on the basis of the deviance
1-pchisq(20.646, 29)
model3 = glm(vs ~ mpg, data = mtcars, family = binomial())
summary(model3)
anova(model3, model2, test = "Chisq")
1 - pchisq(25.533 - 20.646, 1) # p-value of the deviance difference
est.values = predict(model2)
head(est.values)
est.probs = predict(model2, type = "response") # or model2$fitted.values
head(est.probs)
plot(mpg, vs, col = am, xlab = "mpg", ylab = "vs")
curve(predict(model2, newdata = data.frame(mpg = x, am = "0"), type = "response"), add = TRUE)
vs
?is.factor
x
curve(predict(model2, newdata = data.frame(mpg = x, am = "1"), type = "response"), add = TRUE)
plot(mpg, vs, col = am, xlab = "mpg", ylab = "vs")
curve(predict(model2, newdata = data.frame(mpg = x, am = "0"), type = "response"), add = TRUE)
curve(predict(model2, newdata = data.frame(mpg = x, am = "1"), type = "response"), add = TRUE, lty = 2, col = 2)
preds = rep(0, nrow(mtcars))
preds[est.probs > 0.5] = 1
preds
table(preds, vs)
addmargins(table(preds, vs))
7 / 32
mean(preds == vs)
mean(preds != vs)
n = nrow(mtcars)
n
set.seed(222)
selection = sample(n, 0.6 * n, replace = FALSE)
selection
length(selection)
?sample
selection
training.set = mtcars[selection,]
test.set = mtcars[-selection,]
training.set
test.set
model.train = glm(vs ~ mpg + am, data = training.set, family = binomial())
summary(model.train)
probs.test = predict(model.train, newdata = test.set, type = "response")
preds.test = rep(0, length(probs.test))
preds.test[probs.test > 0.5] = 1
addmargins(table(preds.test, vs))
addmargins(table(preds.test, vs[-selection]))
addmargins(table(preds.test, test.set$vs))
mean(preds.test != test.set$vs)
set.seed(1)
selection = sample(n, 0.6 * n, replace = FALSE)
selection
training.set = mtcars[selection,]
test.set = mtcars[-selection,]
model.train = glm(vs ~ mpg + am, data = training.set, family = binomial())
summary(model.train)
probs.test = predict(model.train, newdata = test.set, type = "response")
preds.test = rep(0, length(probs.test))
preds.test[probs.test > 0.5] = 1
addmargins(table(preds.test, test.set$vs))
mean(preds.test != test.set$vs)
set.seed(10)
selection = sample(n, 0.6 * n, replace = FALSE)
selection
training.set = mtcars[selection,]
test.set = mtcars[-selection,]
model.train = glm(vs ~ mpg + am, data = training.set, family = binomial())
summary(model.train)
probs.test = predict(model.train, newdata = test.set, type = "response")
preds.test = rep(0, length(probs.test))
preds.test[probs.test > 0.5] = 1
addmargins(table(preds.test, test.set$vs))
mean(preds.test != test.set$vs)
set.seed(100)
selection = sample(n, 0.6 * n, replace = FALSE)
selection
training.set = mtcars[selection,]
test.set = mtcars[-selection,]
model.train = glm(vs ~ mpg + am, data = training.set, family = binomial())
summary(model.train)
probs.test = predict(model.train, newdata = test.set, type = "response")
preds.test = rep(0, length(probs.test))
preds.test[probs.test > 0.5] = 1
addmargins(table(preds.test, test.set$vs))
mean(preds.test != test.set$vs)
set.seed(222)
selection = sample(n, 0.6 * n, replace = FALSE)
selection
training.set = mtcars[selection,]
test.set = mtcars[-selection,]
model.train = glm(vs ~ mpg + am, data = training.set, family = binomial())
summary(model.train)
probs.test = predict(model.train, newdata = test.set, type = "response")
preds.test = rep(0, length(probs.test))
preds.test[probs.test > 0.5] = 1
addmargins(table(preds.test, test.set$vs))
mean(preds.test != test.set$vs)
library(MASS)
## LDA
library(MASS)
model = lda(vs ~ mpg + am, data = training.set)
model
plot(model)
preds.lda = predict(model, test.set)
preds.lda
preds.lda = predict(model, newdata = test.set)
preds.lda
probs.lda = predict(model, newdata = test.set)
preds.lda = rep(0, nrow(test.set))
probs.lda = predict(model, newdata = test.set)
probs.lda$posterior
preds.lda[probs.lda$posterior[, 2] > 0.5] = 1
addmargins(table(preds.lda, test.set$vs))
mean(preds.lda != test.set$vs)
preds.lda2 = rep(0, nrow(test.set))
preds.lda2[probs.lda$posterior[, 2] > 0.2] = 1
addmargins(table(preds.lda2, test.set$vs))
mean(preds.lda2 != test.set$vs)
library(pROC)
install.packages("pROC")
library(pROC)
values.roc = roc(test.set$vs, probs.lda[, 2])
values.roc = roc(test.set$vs, probs.lda[, 2])
values.roc = roc(test.set$vs, probs.lda$posterior[, 2])
values.roc
names(values.roc)
values.roc$sensitivities
values.roc$specificities
plot(values.roc)
plot(values.roc. print.auc = TRUE)
plot(values.roc, print.auc = TRUE)
mean(preds.lda != test.set$vs)
model.qda = qda(vs ~ mpg + am, data = training.set)
model.qda
probs.qda = predict(model.qda, test.set)
probs.qda
addmargins(table(probs.qda$class, test.set$vs))
mean(probs.qda$class != test.set$vs)
values.rc = roc(test.set$vs, probs.qda$posterior[, 2])
values.roc
values.roc = roc(test.set$vs, probs.qda$posterior[, 2])
values.roc
library(ISLR)
data(Auto)
dim(Auto)
View(Auto)
median.mpg = median(Auto$mpg)
new.mpg = rep(1, length(Auto$mpg))
new.mpg[Auto$mpg < median.mpg] = 0
new.auto = data.frame(new.mpg = new.mpg, Auto[, c("displacement", "horsepower", "origin")])
is.factor(new.auto$origin)
new.auto$origin = as.factor(new.auto$origin)
levels(new.auto$origin) = c("America", "Europe", "Japan")
View(new.auto)
is.factor(new.auto$origin)
?levels
par(mfrow = c(2, 2))
attach(new.auto)
?attach
boxplot(displacement ~ new.mpg, data = new.auto)
boxplot(displacement ~ new.mpg, data = new.auto)
boxplot(displacement ~ new.mpg, data = new.auto, subset = new.auto$origin == "America")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "America")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "Europe")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "Japan")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "Europe")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "Japan")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "Europe")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "America")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "Europe")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "America")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "Europe")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "Japan")
boxplot(horsepower ~ new.mpg, data = new.auto, subset = origin == "America")
boxplot(horsepower ~ new.mpg, data = new.auto, subset = origin == "Europe")
boxplot(horsepower ~ new.mpg, data = new.auto, subset = origin == "America")
boxplot(horsepower ~ new.mpg, data = new.auto, subset = origin == "Europe")
boxplot(horsepower ~ new.mpg, data = new.auto, subset = origin == "Japan")
mosaicplot(table(origin, new.mpg), las = 1)
table(origin, new.mpg)
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "Japan")
mosaicplot(table(origin, new.mpg), las = 1)
table(origin, new.mpg)
m.auto = glm(new.mpg ~ displacement * origin + horsepower * origin, data = new.auto, family = binomial())
summary(m.auto)
1 - pchisq(195.72, 383)
rm(list = ls())
data("mtcars")
names(mtcars)
dim(mtcars)
attach(mtcars)
is.factor(am)
mtcars$am = as.factor(am)
attach(mtcars)
boxplot(mpg ~ vs, xlab = "vs", ylab = "mpg")
boxplot(mpg ~ vs * am, ylab = "mpg", xlab = "vs & am")
model = glm(vs ~ mpg * am, data = mtcars, family = binomial)
summary(model)
model2 = glm(vs ~ mpg + am, family = binomial, data = mtcars)
summary(model2)
coefs = coef(model2)
se = sqrt(diag(vcov(model2)))
c(coefs[2] - qnorm((1 + 0.9) / 2) * se[2], coefs[2] + qnorm((1 + 0.9) / 2) * se[2])
confint(model2, level = 0.9)
# accuracy of model on the basis of the deviance
1-pchisq(20.646, 29)
model3 = glm(vs ~ mpg, data = mtcars, family = binomial())
summary(model3)
anova(model3, model2, test = "Chisq")
1 - pchisq(25.533 - 20.646, 1) # p-value of the deviance difference
est.values = predict(model2)
head(est.values)
est.probs = predict(model2, type = "response") # or model2$fitted.values
head(est.probs)
plot(mpg, vs, col = am, xlab = "mpg", ylab = "vs")
curve(predict(model2, newdata = data.frame(mpg = x, am = "0"), type = "response"), add = TRUE)
curve(predict(model2, newdata = data.frame(mpg = x, am = "1"), type = "response"), add = TRUE, lty = 2, col = 2)
preds = rep(0, nrow(mtcars))
preds[est.probs > 0.5] = 1
preds
addmargins(table(preds, vs))
7 / 32 # error rate
mean(preds != vs) # error rate
n = nrow(mtcars)
set.seed(222)
selection = sample(n, 0.6 * n, replace = FALSE)
selection
training.set = mtcars[selection,]
test.set = mtcars[-selection,]
model.train = glm(vs ~ mpg + am, data = training.set, family = binomial())
summary(model.train)
probs.test = predict(model.train, newdata = test.set, type = "response")
preds.test = rep(0, length(probs.test))
preds.test[probs.test > 0.5] = 1
addmargins(table(preds.test, test.set$vs))
mean(preds.test != test.set$vs)
## LDA
library(MASS)
model = lda(vs ~ mpg + am, data = training.set)
model
plot(model)
probs.lda = predict(model, newdata = test.set)
preds.lda = rep(0, nrow(test.set))
preds.lda[probs.lda$posterior[, 2] > 0.5] = 1
addmargins(table(preds.lda, test.set$vs))
mean(preds.lda != test.set$vs)
preds.lda2 = rep(0, nrow(test.set))
preds.lda2[probs.lda$posterior[, 2] > 0.2] = 1
addmargins(table(preds.lda2, test.set$vs))
mean(preds.lda2 != test.set$vs)
library(pROC)
values.roc = roc(test.set$vs, probs.lda$posterior[, 2])
values.roc
names(values.roc)
values.roc$sensitivities
values.roc$specificities
plot(values.roc, print.auc = TRUE)
model.qda = qda(vs ~ mpg + am, data = training.set)
model.qda
probs.qda = predict(model.qda, test.set)
probs.qda
addmargins(table(probs.qda$class, test.set$vs))
mean(probs.qda$class != test.set$vs)
values.roc = roc(test.set$vs, probs.qda$posterior[, 2])
values.roc
1 - pchisq(25.533 - 20.646, 1) # p-value of the deviance difference
rm(list = ls())
data("mtcars")
names(mtcars)
dim(mtcars)
attach(mtcars)
is.factor(am)
mtcars$am = as.factor(am)
attach(mtcars)
boxplot(mpg ~ vs, xlab = "vs", ylab = "mpg")
boxplot(mpg ~ vs * am, ylab = "mpg", xlab = "vs & am")
model = glm(vs ~ mpg * am, data = mtcars, family = binomial)
summary(model)
model2 = glm(vs ~ mpg + am, family = binomial, data = mtcars)
summary(model2)
coefs = coef(model2)
se = sqrt(diag(vcov(model2)))
c(coefs[2] - qnorm((1 + 0.9) / 2) * se[2], coefs[2] + qnorm((1 + 0.9) / 2) * se[2])
confint(model2, level = 0.9)
# accuracy of model on the basis of the deviance
1-pchisq(20.646, 29)
model3 = glm(vs ~ mpg, data = mtcars, family = binomial())
summary(model3)
anova(model3, model2, test = "Chisq")
1 - pchisq(25.533 - 20.646, 1) # p-value of the deviance difference
rm(list = ls())
library(ISLR)
data(Auto)
dim(Auto)
View(Auto)
median.mpg = median(Auto$mpg)
new.mpg = rep(1, length(Auto$mpg))
new.mpg[Auto$mpg < median.mpg] = 0
new.auto = data.frame(new.mpg = new.mpg, Auto[, c("displacement", "horsepower", "origin")])
is.factor(new.auto$origin)
new.auto$origin = as.factor(new.auto$origin)
# change the names of the levels of the factor
levels(new.auto$origin) = c("America", "Europe", "Japan")
attach(new.auto)
par(mfrow = c(2, 2))
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "America")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "Europe")
boxplot(displacement ~ new.mpg, data = new.auto, subset = origin == "Japan")
boxplot(horsepower ~ new.mpg, data = new.auto, subset = origin == "America")
boxplot(horsepower ~ new.mpg, data = new.auto, subset = origin == "Europe")
boxplot(horsepower ~ new.mpg, data = new.auto, subset = origin == "Japan")
mosaicplot(table(origin, new.mpg), las = 1)
table(origin, new.mpg)
m.auto = glm(new.mpg ~ displacement * origin + horsepower * origin, data = new.auto, family = binomial())
summary(m.auto)
1 - pchisq(195.72, 383)
1 - pchisq(195.72, 383)
m.auto2 = glm(new.mpg ~ displacement + origin + horsepower, data = new.auto, family = binomial())
summary(m.auto2)
anova(m.auto2, m.auto)
anova(m.auto2, m.auto, test = "Chisq")
dim(new.auto)
1 - pchisq(195.72, 383)
anova(m.auto2, m.auto, test = "Chisq")
est.values = predict(m.auto)
est.probs = predict(m.auto, type = "response")
preds = rep(0, nrow(new.auto))
preds[est.probs > .5] = 1
addmargins(table(preds, new.mpg))
mean(preds != new.mpg)
rm(list = ls())
library(rattle.data)
attach(wine)
dim(wine)
View(wine)
?wine
barplot(table(Type))
pie(table(Type))
pairs(wine[, 8:13])
pairs(wine[, 2:7])
wine.lda = lda(Type ~ ., data = wine)
library(MASS)
wine.lda = lda(Type ~ ., data = wine)
wine.lda
plot(wine.lda)
wine.previsioni = predict(wine.lda)
ldahist(data = wine.previsioni$x[, 1], g = wine$Type)
ldahist(data = wine.previsioni$x[, 2], g = wine$Type)
wine.previsioni
names(wine.previsioni)
wine.previsioni$posterior
